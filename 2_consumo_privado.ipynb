{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wm5aGTMvpUY-"
   },
   "source": [
    "# 2. consumo_privado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1414,
     "status": "ok",
     "timestamp": 1730862325866,
     "user": {
      "displayName": "Diego Alberto Morales Ibañez",
      "userId": "13208052402867133978"
     },
     "user_tz": 360
    },
    "id": "m3I5xyHcxtWI",
    "outputId": "bdf501de-b594-4468-9b99-2d2359deb120"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from itertools import product\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from functools import partial\n",
    "import joblib\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "cwd_path = os.getcwd()\n",
    "data_path = os.path.join(cwd_path, 'data')\n",
    "input_path = os.path.join(data_path, 'input')\n",
    "output_path = os.path.join(data_path, 'output')\n",
    "target_var = 'consumo_privado'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para obtener el trimestre al que pertenece el mes y la fecha\n",
    "# del último mes del trimestre respectivo\n",
    "def get_last_day_of_quarter(date):\n",
    "    quarter = date.quarter\n",
    "    year = date.year\n",
    "    if quarter == 1:\n",
    "        return pd.Timestamp(f'{year}-03-31')\n",
    "    elif quarter == 2:\n",
    "        return pd.Timestamp(f'{year}-06-30')\n",
    "    elif quarter == 3:\n",
    "        return pd.Timestamp(f'{year}-09-30')\n",
    "    else:\n",
    "        return pd.Timestamp(f'{year}-12-31')\n",
    "# función para sumar si no hay ningún valor nulo o devolver nulo de lo contrario\n",
    "def sum_or_nan(x):\n",
    "    return np.nan if x.isna().any() else x.sum()\n",
    "# función para promediar si no hay ningún valor nulo o devolver nulo de lo contrario\n",
    "def mean_or_nan(x):\n",
    "    return np.nan if x.isna().any() else x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se lee la metadata\n",
    "metadata_path = os.path.join(cwd_path,'metadatos.xlsx')\n",
    "variables = pd.read_excel(metadata_path)\n",
    "# se agrega el tipo de función de agregación dependiendo de la naturaleza\n",
    "# de la variable\n",
    "variables['agg_func'] = np.where(variables.subsector.isin(['tipo_de_cambio', 'tasa_lider', 'tasa_de_interes', 'indice_mensual_actividad_economica', 'inflacion_de_guatemala']),\n",
    "                                 mean_or_nan, sum_or_nan)\n",
    "\n",
    "# se toman las filas donde la componente tiene un 1\n",
    "filtro_componente = (variables[target_var]\n",
    "                     .fillna(0)\n",
    "                     .astype(bool))\n",
    "variables_componente = variables[filtro_componente].reset_index(drop=True)\n",
    "# se dividen las variables en periodicidades trimestrales y no trimestrales\n",
    "variables_componente_trimestrales = variables_componente[variables_componente.frecuencia.str.lower() == 'trimestral'].reset_index(drop=True)\n",
    "variables_componente_no_trimestrales = variables_componente[variables_componente.frecuencia.str.lower() != 'trimestral'].reset_index(drop=True)\n",
    "\n",
    "# se crea el diccionario para leer los archivos csv de las variables trimestrales\n",
    "input_files_trimestrales = {}\n",
    "for idx, row in variables_componente_trimestrales.iterrows():\n",
    "  input_files_trimestrales[row.variable] = [row.sector, row.subsector, f'{row.variable}.csv']\n",
    "# se leen las variables\n",
    "input_list_trimestrales = []\n",
    "for name, path in input_files_trimestrales.items():\n",
    "  file_path = os.path.join(input_path, *path)\n",
    "  df_input = (pd\n",
    "                .read_csv(file_path, sep=',')\n",
    "                .rename(columns={'Fecha': 'fa', 'Valor': name})\n",
    "                .assign(fa = lambda df: pd.to_datetime(df['fa'], dayfirst=True))\n",
    "                .set_index('fa')\n",
    "                )\n",
    "  input_list_trimestrales.append(df_input)\n",
    "# se crea el dataframe\n",
    "try:\n",
    "  df_trimestrales = pd.concat(input_list_trimestrales, axis=1, join='outer')\n",
    "except ValueError:\n",
    "  df_trimestrales = pd.DataFrame()\n",
    "\n",
    "# se crea el diccionario para leer los archivos csv de las variables no trimestrales\n",
    "input_files_no_trimestrales = {}\n",
    "for idx, row in variables_componente_no_trimestrales.iterrows():\n",
    "  input_files_no_trimestrales[row.variable] = [row.sector, row.subsector, f'{row.variable}.csv']\n",
    "# se leen las variables\n",
    "input_list_no_trimestrales = []\n",
    "for name, path in input_files_no_trimestrales.items():\n",
    "  file_path = os.path.join(input_path, *path)\n",
    "  df_input = (pd\n",
    "                .read_csv(file_path, sep=',')\n",
    "                .rename(columns={'Fecha': 'fa', 'Valor': name})\n",
    "                .assign(fa = lambda df: pd.to_datetime(df['fa'], dayfirst=True))\n",
    "                .set_index('fa')\n",
    "                )\n",
    "  input_list_no_trimestrales.append(df_input)\n",
    "# se crea el dataframe\n",
    "try:\n",
    "  df_no_trimestrales = pd.concat(input_list_no_trimestrales, axis=1, join='outer')\n",
    "  # se transforman las variables no trimestrales a trimestrales\n",
    "  agg_vars = dict()\n",
    "  for column in df_no_trimestrales.columns:\n",
    "    agg_vars[column] = variables[variables.variable == column].agg_func.values[0]\n",
    "  df_no_trimestrales['fa'] = df_no_trimestrales.index\n",
    "  df_no_trimestrales.fa = df_no_trimestrales.fa.apply(get_last_day_of_quarter)\n",
    "  df_no_trimestrales.reset_index(drop=True, inplace=True)\n",
    "  df_no_trimestrales = df_no_trimestrales.groupby('fa').agg(agg_vars)\n",
    "except ValueError:\n",
    "  df_no_trimestrales = pd.DataFrame()\n",
    "\n",
    "# se unen las variables trimestrales con las no trimestrales transformadas\n",
    "df_list = []\n",
    "if len(df_trimestrales) > 0:\n",
    "  df_list.append(df_trimestrales)\n",
    "if len(df_no_trimestrales) > 0:\n",
    "  df_list.append(df_no_trimestrales)\n",
    "\n",
    "df = pd.concat(df_list, axis=1, join='outer')\n",
    "df.dropna(inplace=True)\n",
    "output_filepath = os.path.join(output_path, f'{target_var}_dataset.xlsx')\n",
    "df.to_excel(output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipc_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-10-31</th>\n",
       "      <td>-0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-11-30</th>\n",
       "      <td>-0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-31</th>\n",
       "      <td>-0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>1.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-30</th>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-31</th>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-31</th>\n",
       "      <td>3.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-30</th>\n",
       "      <td>2.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-31</th>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ipc_total\n",
       "fa                   \n",
       "2009-10-31      -0.65\n",
       "2009-11-30      -0.61\n",
       "2009-12-31      -0.28\n",
       "2010-01-31       1.43\n",
       "2010-02-28       2.48\n",
       "...               ...\n",
       "2024-06-30       3.62\n",
       "2024-07-31       3.78\n",
       "2024-08-31       3.07\n",
       "2024-09-30       2.11\n",
       "2024-10-31       1.16\n",
       "\n",
       "[181 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list_no_trimestrales[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gasto_consumo_final_hogar_isflsh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-06-30</th>\n",
       "      <td>7645.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-09-30</th>\n",
       "      <td>8728.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-31</th>\n",
       "      <td>9664.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>7904.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30</th>\n",
       "      <td>8587.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-30</th>\n",
       "      <td>23129.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30</th>\n",
       "      <td>23189.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>24929.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-31</th>\n",
       "      <td>20670.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-30</th>\n",
       "      <td>21631.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gasto_consumo_final_hogar_isflsh\n",
       "fa                                          \n",
       "2009-06-30                           7645.80\n",
       "2009-09-30                           8728.90\n",
       "2009-12-31                           9664.60\n",
       "2010-03-31                           7904.40\n",
       "2010-06-30                           8587.80\n",
       "...                                      ...\n",
       "2023-06-30                          23129.23\n",
       "2023-09-30                          23189.90\n",
       "2023-12-31                          24929.79\n",
       "2024-03-31                          20670.85\n",
       "2024-06-30                          21631.61\n",
       "\n",
       "[61 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trimestrales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipc_total</th>\n",
       "      <th>tasa_int_lider_pm</th>\n",
       "      <th>oper_estab_mon_me</th>\n",
       "      <th>oper_estab_mon_mn</th>\n",
       "      <th>egreso_div_cap_imp</th>\n",
       "      <th>egreso_div_servicios_trans</th>\n",
       "      <th>egreso_div_transf_donaciones</th>\n",
       "      <th>egreso_div_turismo_viajes</th>\n",
       "      <th>ingreso_div_exp</th>\n",
       "      <th>ingreso_div_servicios_seg</th>\n",
       "      <th>...</th>\n",
       "      <th>taxs</th>\n",
       "      <th>comunic</th>\n",
       "      <th>finan</th>\n",
       "      <th>inmob</th>\n",
       "      <th>act_profes</th>\n",
       "      <th>servicios</th>\n",
       "      <th>ensenanza</th>\n",
       "      <th>salud</th>\n",
       "      <th>otr_act</th>\n",
       "      <th>tipo_cambio_de_referencia_gtq_usd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-09-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1505896.7</td>\n",
       "      <td>7484.1</td>\n",
       "      <td>10211.9</td>\n",
       "      <td>125283.0</td>\n",
       "      <td>727724.2</td>\n",
       "      <td>7180.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.186359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.003248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-09-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.030767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.831462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.810840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.770799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.740886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.725593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ipc_total  tasa_int_lider_pm  oper_estab_mon_me  \\\n",
       "fa                                                            \n",
       "2009-09-30        NaN                NaN                NaN   \n",
       "2009-12-31        NaN                NaN                NaN   \n",
       "2010-03-31        NaN                NaN                NaN   \n",
       "2010-06-30        NaN                NaN                NaN   \n",
       "2010-09-30        NaN                NaN                NaN   \n",
       "...               ...                ...                ...   \n",
       "2023-12-31        NaN                NaN                NaN   \n",
       "2024-03-31        NaN                NaN                NaN   \n",
       "2024-06-30        NaN                NaN                NaN   \n",
       "2024-09-30        NaN                NaN                NaN   \n",
       "2024-12-31        NaN                NaN                NaN   \n",
       "\n",
       "            oper_estab_mon_mn  egreso_div_cap_imp  egreso_div_servicios_trans  \\\n",
       "fa                                                                              \n",
       "2009-09-30                NaN           1505896.7                      7484.1   \n",
       "2009-12-31                NaN                 NaN                         NaN   \n",
       "2010-03-31                NaN                 NaN                         NaN   \n",
       "2010-06-30                NaN                 NaN                         NaN   \n",
       "2010-09-30                NaN                 NaN                         NaN   \n",
       "...                       ...                 ...                         ...   \n",
       "2023-12-31                NaN                 NaN                         NaN   \n",
       "2024-03-31                NaN                 NaN                         NaN   \n",
       "2024-06-30                NaN                 NaN                         NaN   \n",
       "2024-09-30                NaN                 NaN                         NaN   \n",
       "2024-12-31                NaN                 NaN                         NaN   \n",
       "\n",
       "            egreso_div_transf_donaciones  egreso_div_turismo_viajes  \\\n",
       "fa                                                                    \n",
       "2009-09-30                       10211.9                   125283.0   \n",
       "2009-12-31                           NaN                        NaN   \n",
       "2010-03-31                           NaN                        NaN   \n",
       "2010-06-30                           NaN                        NaN   \n",
       "2010-09-30                           NaN                        NaN   \n",
       "...                                  ...                        ...   \n",
       "2023-12-31                           NaN                        NaN   \n",
       "2024-03-31                           NaN                        NaN   \n",
       "2024-06-30                           NaN                        NaN   \n",
       "2024-09-30                           NaN                        NaN   \n",
       "2024-12-31                           NaN                        NaN   \n",
       "\n",
       "            ingreso_div_exp  ingreso_div_servicios_seg  ...  taxs  comunic  \\\n",
       "fa                                                      ...                  \n",
       "2009-09-30         727724.2                     7180.9  ...   NaN      NaN   \n",
       "2009-12-31              NaN                        NaN  ...   NaN      NaN   \n",
       "2010-03-31              NaN                        NaN  ...   NaN      NaN   \n",
       "2010-06-30              NaN                        NaN  ...   NaN      NaN   \n",
       "2010-09-30              NaN                        NaN  ...   NaN      NaN   \n",
       "...                     ...                        ...  ...   ...      ...   \n",
       "2023-12-31              NaN                        NaN  ...   NaN      NaN   \n",
       "2024-03-31              NaN                        NaN  ...   NaN      NaN   \n",
       "2024-06-30              NaN                        NaN  ...   NaN      NaN   \n",
       "2024-09-30              NaN                        NaN  ...   NaN      NaN   \n",
       "2024-12-31              NaN                        NaN  ...   NaN      NaN   \n",
       "\n",
       "            finan  inmob  act_profes  servicios  ensenanza  salud  otr_act  \\\n",
       "fa                                                                           \n",
       "2009-09-30    NaN    NaN         NaN        NaN        NaN    NaN      NaN   \n",
       "2009-12-31    NaN    NaN         NaN        NaN        NaN    NaN      NaN   \n",
       "2010-03-31    NaN    NaN         NaN        NaN        NaN    NaN      NaN   \n",
       "2010-06-30    NaN    NaN         NaN        NaN        NaN    NaN      NaN   \n",
       "2010-09-30    NaN    NaN         NaN        NaN        NaN    NaN      NaN   \n",
       "...           ...    ...         ...        ...        ...    ...      ...   \n",
       "2023-12-31    NaN    NaN         NaN        NaN        NaN    NaN      NaN   \n",
       "2024-03-31    NaN    NaN         NaN        NaN        NaN    NaN      NaN   \n",
       "2024-06-30    NaN    NaN         NaN        NaN        NaN    NaN      NaN   \n",
       "2024-09-30    NaN    NaN         NaN        NaN        NaN    NaN      NaN   \n",
       "2024-12-31    NaN    NaN         NaN        NaN        NaN    NaN      NaN   \n",
       "\n",
       "            tipo_cambio_de_referencia_gtq_usd  \n",
       "fa                                             \n",
       "2009-09-30                                NaN  \n",
       "2009-12-31                                NaN  \n",
       "2010-03-31                           8.186359  \n",
       "2010-06-30                           8.003248  \n",
       "2010-09-30                           8.030767  \n",
       "...                                       ...  \n",
       "2023-12-31                           7.831462  \n",
       "2024-03-31                           7.810840  \n",
       "2024-06-30                           7.770799  \n",
       "2024-09-30                           7.740886  \n",
       "2024-12-31                           7.725593  \n",
       "\n",
       "[62 rows x 69 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_trimestrales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gasto_consumo_final_hogar_isflsh</th>\n",
       "      <th>ipc_total</th>\n",
       "      <th>tasa_int_lider_pm</th>\n",
       "      <th>oper_estab_mon_me</th>\n",
       "      <th>oper_estab_mon_mn</th>\n",
       "      <th>egreso_div_cap_imp</th>\n",
       "      <th>egreso_div_servicios_trans</th>\n",
       "      <th>egreso_div_transf_donaciones</th>\n",
       "      <th>egreso_div_turismo_viajes</th>\n",
       "      <th>ingreso_div_exp</th>\n",
       "      <th>...</th>\n",
       "      <th>taxs</th>\n",
       "      <th>comunic</th>\n",
       "      <th>finan</th>\n",
       "      <th>inmob</th>\n",
       "      <th>act_profes</th>\n",
       "      <th>servicios</th>\n",
       "      <th>ensenanza</th>\n",
       "      <th>salud</th>\n",
       "      <th>otr_act</th>\n",
       "      <th>tipo_cambio_de_referencia_gtq_usd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [gasto_consumo_final_hogar_isflsh, ipc_total, tasa_int_lider_pm, oper_estab_mon_me, oper_estab_mon_mn, egreso_div_cap_imp, egreso_div_servicios_trans, egreso_div_transf_donaciones, egreso_div_turismo_viajes, ingreso_div_exp, ingreso_div_servicios_seg, ingreso_div_servicios_trans, ingreso_div_transf_donaciones, ingreso_div_turismo_viajes, cif_imp_com_exterior, cif_imp_cap_ind_telecom_constru, cif_imp_cap_transporte, cif_imp_cap_agricultura, cif_imp_con_duradero, cif_imp_con_no_duradero, cif_imp_con_no_semiduradero, cif_imp_combustible_aceites_min, cif_imp_mat_primas_prod_agric, cif_imp_mat_primas_prod_indus, cif_imp_mat_construccion, gastos_corrientes_gob_ctral, gastos_cap_gob_ctral, gastos_totales_gob_ctral, ingresos_no_trib_gob_ctral, ingresos_totales_gob_ctral, ingresos_trib_gob, cred_sec_priv_me, cred_sec_priv_mn, cred_sec_priv_total, emision_monetaria, medio_circulante, medios_pago_me, medios_pago_mn, medios_pago_totales, numerario_circulacion, tid_activa_me, tid_activa_mn, tid_cdps_me, tid_cdps_mn, tid_ahorro_me, tid_ahorro_mn, tid_desc_me, tid_desc_mn, tid_oblig_me, tid_oblig_mn, tid_prest_mn, tid_prest_me, tid_pasiva_me, tid_pasiva_mn, agro, elect, construc, comers, transport, hosped, taxs, comunic, finan, inmob, act_profes, servicios, ensenanza, salud, otr_act, tipo_cambio_de_referencia_gtq_usd]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 70 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvi02qwhziG0"
   },
   "source": [
    "## Procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1730863050969,
     "user": {
      "displayName": "Diego Alberto Morales Ibañez",
      "userId": "13208052402867133978"
     },
     "user_tz": 360
    },
    "id": "m8cASV9BbpH1"
   },
   "outputs": [],
   "source": [
    "def data_processing(df, target_var, t_samples, keep_all):\n",
    "    df_shifted = df[[target_var]].copy()\n",
    "    for n in range(1, t_samples + 1):\n",
    "        for col in df.columns:\n",
    "            df_shifted[f'{col}_t_{n}'] = df[col].shift(n)\n",
    "    df_shifted = df_shifted.dropna()\n",
    "\n",
    "    for col in df.columns:\n",
    "        df_shifted[f'{col}_prom_{t_samples}'] = df_shifted[[f'{col}_t_{i}' for i in range(1, t_samples + 1)]].mean(axis=1)\n",
    "        df_shifted[f'{col}_desv_{t_samples}'] = df_shifted[[f'{col}_t_{i}' for i in range(1, t_samples + 1)]].std(axis=1)\n",
    "        df_shifted[f'{col}_min_{t_samples}'] = df_shifted[[f'{col}_t_{i}' for i in range(1, t_samples + 1)]].min(axis=1)\n",
    "        df_shifted[f'{col}_max_{t_samples}'] = df_shifted[[f'{col}_t_{i}' for i in range(1, t_samples + 1)]].max(axis=1)\n",
    "        df_shifted[f'{col}_sum_{t_samples}'] = df_shifted[[f'{col}_t_{i}' for i in range(1, t_samples + 1)]].sum(axis=1)\n",
    "\n",
    "    if not keep_all:\n",
    "        columns_to_keep = [target_var] + [f'{col}_t_{1}' for col in df.columns] + \\\n",
    "                          [f'{col}_{agg}_{t_samples}' for col in df.columns for agg in ['prom', 'desv', 'min', 'max', 'sum']]\n",
    "        df_shifted = df_shifted[columns_to_keep]\n",
    "\n",
    "    return df_shifted\n",
    "\n",
    "df_shifted = data_processing(df, target_var, 4*3, keep_all=False)\n",
    "\n",
    "X = df_shifted.drop(columns=[target_var])\n",
    "y = df_shifted[target_var]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    X_train_scaled, \n",
    "    index=X_train.index,\n",
    "    columns=X_train.columns\n",
    ")\n",
    "\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    X_test_scaled, \n",
    "    index=X_test.index, \n",
    "    columns=X_test.columns\n",
    ")\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "X_train_pca = pd.DataFrame(\n",
    "    X_train_pca,\n",
    "    index=X_train.index,\n",
    "    columns=[f'PC{i+1}' for i in range(X_train_pca.shape[1])]\n",
    ")\n",
    "\n",
    "X_test_pca = pd.DataFrame(\n",
    "    X_test_pca,\n",
    "    index=X_test.index,\n",
    "    columns=[f'PC{i+1}' for i in range(X_test_pca.shape[1])]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_arima(y_train, X_train, p_values, d_values, q_values):\n",
    "    best_score, best_params, best_model = float(\"inf\"), None, None\n",
    "    \n",
    "    for p, d, q in product(p_values, d_values, q_values):\n",
    "        try:\n",
    "            model = ARIMA(y_train, order=(p, d, q), exog=X_train).fit()\n",
    "            if model.aic < best_score:\n",
    "                best_score, best_params, best_model = model.aic, (p, d, q), model\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    return best_model, best_params\n",
    "\n",
    "def arquitectura_ann(cant_capas, cant_neurons, learning_rate, input_dim):\n",
    "    model = Sequential([Input(shape=(input_dim,))])\n",
    "    for _ in range(cant_capas):\n",
    "        model.add(Dense(cant_neurons, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model\n",
    "\n",
    "def optimizar_ann(trial, X_train, y_train):\n",
    "    cant_capas = trial.suggest_int('cant_capas', 2, 8, 2)\n",
    "    cant_neurons = trial.suggest_int('cant_neurons', 8, 64, 8)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "    learning_rate = trial.suggest_categorical('learning_rate', [0.001,0.01, 0.1])\n",
    "    \n",
    "    model = arquitectura_ann(cant_capas, cant_neurons, learning_rate, X_train.shape[1])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    history = model.fit(\n",
    "        X_train, y_train, \n",
    "        validation_split=0.2,\n",
    "        epochs=100, batch_size=batch_size, verbose=0, callbacks=[early_stopping]\n",
    "    )\n",
    "    return min(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17224,
     "status": "ok",
     "timestamp": 1730866814305,
     "user": {
      "displayName": "Diego Alberto Morales Ibañez",
      "userId": "13208052402867133978"
     },
     "user_tz": 360
    },
    "id": "BNYnYkq3gdtm",
    "outputId": "c15db2f6-577e-4a81-a520-1644cdc833c0"
   },
   "outputs": [],
   "source": [
    "def train_models(X_train, X_test, y_train, y_test):\n",
    "    seed_value = 42\n",
    "    best_models = {}\n",
    "\n",
    "    p_values = range(1, 4)\n",
    "    model_ar, best_ar_params = optimize_arima(y_train.asfreq('QE'), X_train.asfreq('QE'), p_values, [0], [0])\n",
    "    best_models['ar'] = model_ar\n",
    "    print(f\"AR Best Parameters: {best_ar_params}\")\n",
    "\n",
    "    p_values = range(1, 4)\n",
    "    d_values = range(1, 4)\n",
    "    q_values = range(1, 4)\n",
    "    model_arima, best_arima_params = optimize_arima(y_train.asfreq('QE'), X_train.asfreq('QE'), p_values, d_values, q_values)\n",
    "    best_models['arima'] = model_arima\n",
    "    print(f\"ARIMA Best Parameters: {best_arima_params}\")\n",
    "\n",
    "    params_ridge = {'alpha': [0.1, 1.0, 10],\n",
    "        'random_state': [seed_value]}\n",
    "    grid_ridge = GridSearchCV(Ridge(), params_ridge, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_ridge.fit(X_train, y_train)\n",
    "    best_models['lr'] = grid_ridge.best_estimator_\n",
    "    print(f\"LR Ridge Best Parameters: {grid_ridge.best_params_}\")\n",
    "    \n",
    "    params_knn = {'n_neighbors': [3, 5, 7, 10],\n",
    "                  'weights': ['uniform', 'distance'],\n",
    "                  'metric': ['euclidean', 'manhattan', 'minkowski']}\n",
    "    grid_knn = GridSearchCV(KNeighborsRegressor(),\n",
    "                            params_knn, cv=3, scoring='neg_mean_squared_error',\n",
    "                            n_jobs=-1, verbose=0)\n",
    "    grid_knn.fit(X_train, y_train)\n",
    "    best_models['knn'] = grid_knn.best_estimator_\n",
    "    print(f\"KNN Best Parameters: {grid_knn.best_params_}\")\n",
    "\n",
    "    params_rf = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30],\n",
    "        'min_samples_split': [5, 10, 20],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'random_state': [seed_value]\n",
    "    }\n",
    "    grid_rf = GridSearchCV(RandomForestRegressor(),\n",
    "                           params_rf, cv=3, scoring='neg_mean_squared_error',\n",
    "                           n_jobs=-1, verbose=0)\n",
    "    grid_rf.fit(X_train, y_train)\n",
    "    best_models['rf'] = grid_rf.best_estimator_\n",
    "    print(f\"Random Forest Best Parameters: {grid_rf.best_params_}\")\n",
    "\n",
    "    params_xgb = {\n",
    "        'alpha': [0, 0.1, 1],\n",
    "        'lambda': [0, 0.1, 1],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7, 10, 15],\n",
    "        'random_state': [seed_value]\n",
    "    }\n",
    "    grid_xgb = GridSearchCV(xgb.XGBRegressor(n_jobs=-1),\n",
    "                            params_xgb,\n",
    "                            cv=3, scoring='neg_mean_squared_error',\n",
    "                            verbose=0)\n",
    "    grid_xgb.fit(X_train, y_train)\n",
    "    best_models['xgb'] = grid_xgb.best_estimator_\n",
    "    print(f\"XGBoost Best Parameters: {grid_xgb.best_params_}\")\n",
    "\n",
    "    study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "    study.optimize(\n",
    "        partial(optimizar_ann, X_train=X_train, y_train=y_train),\n",
    "        n_trials=30,\n",
    "        n_jobs=-1,\n",
    "        show_progress_bar=True)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    print(f\"ANN Best Parameters: {best_params}\")\n",
    "\n",
    "    model_ann = arquitectura_ann(best_params['cant_capas'], best_params['cant_neurons'], best_params['learning_rate'], X_train.shape[1])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    model_ann.fit(\n",
    "        X_train, y_train, \n",
    "        validation_split=0.2,\n",
    "        epochs=100, batch_size=best_params['batch_size'], verbose=0, callbacks=[early_stopping]\n",
    "    )\n",
    "    best_models['ann'] = model_ann\n",
    "\n",
    "    return best_models\n",
    "\n",
    "best_models = train_models(X_train_pca, X_test_pca, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 486,
     "status": "ok",
     "timestamp": 1730866840847,
     "user": {
      "displayName": "Diego Alberto Morales Ibañez",
      "userId": "13208052402867133978"
     },
     "user_tz": 360
    },
    "id": "sQjqABQLhIx3",
    "outputId": "86b813a9-80d5-4d51-c5ad-bac56b53fe89"
   },
   "outputs": [],
   "source": [
    "def evaluate(best_models, X_train, y_train, X_test, y_test, target_var):\n",
    "    results = {}\n",
    "    for name, model in best_models.items():\n",
    "        # Predicción y cálculo del MSE en el conjunto de entrenamiento\n",
    "        if name in ('ar', 'arima'):\n",
    "            y_train_pred = model.predict(start=0, end=len(y_train)-1, exog=X_train)\n",
    "        else:\n",
    "            y_train_pred = model.predict(X_train)\n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        \n",
    "        # Predicción y cálculo del MSE en el conjunto de prueba\n",
    "        if name in ('ar', 'arima'):\n",
    "            y_test_pred = model.predict(start=len(y_train), end=len(y_train)+len(y_test)-1, exog=X_test)\n",
    "        else:\n",
    "            y_test_pred = model.predict(X_test)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "        train_rmse = np.sqrt(train_mse)\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        \n",
    "        # Almacenar los resultados\n",
    "        results[name] = {\n",
    "            'y_train_pred': y_train_pred,\n",
    "            'train_rmse': train_rmse,\n",
    "            'y_test_pred': y_test_pred,\n",
    "            'test_rmse': test_rmse\n",
    "        }\n",
    "        \n",
    "        print(f\"{name}: train_rmse={train_rmse:,.2f}, test_rmse={test_rmse:,.2f}\")\n",
    "\n",
    "    best_model_name = min(results, key=lambda x: results[x]['test_rmse'])\n",
    "    best_model = best_models[best_model_name]\n",
    "    print(f\"Mejor modelo: {best_model_name}\")\n",
    "\n",
    "    export_path = os.path.join(output_path, 'models')\n",
    "    with open(os.path.join(export_path ,f\"{target_var}.pkl\"), \"wb\") as f:\n",
    "        joblib.dump(best_model, f)\n",
    "\n",
    "    print(f\"Modelo {target_var} exportado exitosamente.\")\n",
    "    return results\n",
    "\n",
    "results = evaluate(best_models, X_train_pca, y_train, X_test_pca, y_test, target_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1730866934965,
     "user": {
      "displayName": "Diego Alberto Morales Ibañez",
      "userId": "13208052402867133978"
     },
     "user_tz": 360
    },
    "id": "Zd3CRyoQrlCI",
    "outputId": "9d2e854b-3bfc-4440-c9df-95b26b0f6a7c"
   },
   "outputs": [],
   "source": [
    "def plot_comparison(results, target_var):\n",
    "    colors = {'ar' : 'brown',\n",
    "              'arima' : 'blue',\n",
    "              'lr' : 'red',\n",
    "              'knn' : 'orange',\n",
    "              'rf' : 'green',\n",
    "              'xgb' : 'purple',\n",
    "              'ann' : 'pink'}\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(y_test.values, label=\"Valores Reales (y_test)\", color=\"blue\")\n",
    "    \n",
    "    for name, result in results.items():\n",
    "        if name in ('ar', 'arima'):\n",
    "            plt.plot(result['y_test_pred'].reset_index(drop=True), label=f\"y_test_pred_{name}\", color=colors[name], linestyle=\"--\")\n",
    "        else:\n",
    "            plt.plot(result['y_test_pred'], label=f\"y_test_pred_{name}\", color=colors[name], linestyle=\"--\")\n",
    "\n",
    "    plt.xlabel(\"tiempo\")\n",
    "    plt.ylabel(target_var)\n",
    "    plt.title(f\"Resultados {target_var}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(output_path ,f'result_{target_var}.png'), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_comparison(results, target_var)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
