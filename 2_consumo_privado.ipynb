{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wm5aGTMvpUY-"
   },
   "source": [
    "# 2. consumo_privado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1414,
     "status": "ok",
     "timestamp": 1730862325866,
     "user": {
      "displayName": "Diego Alberto Morales Ibañez",
      "userId": "13208052402867133978"
     },
     "user_tz": 360
    },
    "id": "m3I5xyHcxtWI",
    "outputId": "bdf501de-b594-4468-9b99-2d2359deb120"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from itertools import product\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from functools import partial\n",
    "import joblib\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "cwd_path = os.getcwd()\n",
    "data_path = os.path.join(cwd_path, 'data')\n",
    "input_path = os.path.join(data_path, 'input')\n",
    "output_path = os.path.join(data_path, 'output')\n",
    "target_var = 'consumo_privado'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para obtener el trimestre al que pertenece el mes y la fecha\n",
    "# del último mes del trimestre respectivo\n",
    "def get_last_day_of_quarter(date):\n",
    "    quarter = date.quarter\n",
    "    year = date.year\n",
    "    if quarter == 1:\n",
    "        return pd.Timestamp(f'{year}-03-31')\n",
    "    elif quarter == 2:\n",
    "        return pd.Timestamp(f'{year}-06-30')\n",
    "    elif quarter == 3:\n",
    "        return pd.Timestamp(f'{year}-09-30')\n",
    "    else:\n",
    "        return pd.Timestamp(f'{year}-12-31')\n",
    "# función para sumar si no hay ningún valor nulo o devolver nulo de lo contrario\n",
    "def sum_or_nan(x):\n",
    "    return np.nan if x.isna().any() else x.sum()\n",
    "# función para promediar si no hay ningún valor nulo o devolver nulo de lo contrario\n",
    "def mean_or_nan(x):\n",
    "    return np.nan if x.isna().any() else x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se lee la metadata\n",
    "metadata_path = os.path.join(cwd_path,'metadatos.xlsx')\n",
    "variables = pd.read_excel(metadata_path)\n",
    "# se agrega el tipo de función de agregación dependiendo de la naturaleza\n",
    "# de la variable\n",
    "variables['agg_func'] = np.where(variables.subsector.isin(['tipo_de_cambio', 'tasa_lider', 'tasa_de_interes', 'indice_mensual_actividad_economica', 'inflacion_de_guatemala']),\n",
    "                                 mean_or_nan, sum_or_nan)\n",
    "\n",
    "# se toman las filas donde la componente tiene un 1\n",
    "filtro_componente = (variables[target_var]\n",
    "                     .fillna(0)\n",
    "                     .astype(bool))\n",
    "variables_componente = variables[filtro_componente].reset_index(drop=True)\n",
    "# se dividen las variables en periodicidades trimestrales y no trimestrales\n",
    "variables_componente_trimestrales = variables_componente[variables_componente.frecuencia.str.lower() == 'trimestral'].reset_index(drop=True)\n",
    "variables_componente_no_trimestrales = variables_componente[variables_componente.frecuencia.str.lower() != 'trimestral'].reset_index(drop=True)\n",
    "\n",
    "# se crea el diccionario para leer los archivos csv de las variables trimestrales\n",
    "input_files_trimestrales = {}\n",
    "for idx, row in variables_componente_trimestrales.iterrows():\n",
    "  input_files_trimestrales[row.variable] = [row.sector, row.subsector, f'{row.variable}.csv']\n",
    "# se leen las variables\n",
    "input_list_trimestrales = []\n",
    "for name, path in input_files_trimestrales.items():\n",
    "  file_path = os.path.join(input_path, *path)\n",
    "  df_input = (pd\n",
    "                .read_csv(file_path, sep=',')\n",
    "                .rename(columns={'Fecha': 'fa', 'Valor': name})\n",
    "                .assign(fa = lambda df: pd.to_datetime(df['fa'], dayfirst=True))\n",
    "                .set_index('fa')\n",
    "                )\n",
    "  input_list_trimestrales.append(df_input)\n",
    "# se crea el dataframe\n",
    "try:\n",
    "  df_trimestrales = pd.concat(input_list_trimestrales, axis=1, join='outer')\n",
    "except ValueError:\n",
    "  df_trimestrales = pd.DataFrame()\n",
    "\n",
    "# se crea el diccionario para leer los archivos csv de las variables no trimestrales\n",
    "input_files_no_trimestrales = {}\n",
    "for idx, row in variables_componente_no_trimestrales.iterrows():\n",
    "  input_files_no_trimestrales[row.variable] = [row.sector, row.subsector, f'{row.variable}.csv']\n",
    "# se leen las variables\n",
    "input_list_no_trimestrales = []\n",
    "for name, path in input_files_no_trimestrales.items():\n",
    "  agg_vars = dict()\n",
    "  agg_vars[name] = variables[variables.variable == name].agg_func.values[0]\n",
    "  file_path = os.path.join(input_path, *path)\n",
    "  df_input = (pd\n",
    "                .read_csv(file_path, sep=',')\n",
    "                .rename(columns={'Fecha': 'fa', 'Valor': name})\n",
    "                .assign(fa = lambda df: pd.to_datetime(df['fa'], dayfirst=True))\n",
    "                .set_index('fa')\n",
    "                )\n",
    "  df_input['fa'] = df_input.index\n",
    "  df_input.fa = df_input.fa.apply(get_last_day_of_quarter)\n",
    "  df_input.reset_index(drop=True, inplace=True)\n",
    "  df_input = df_input.groupby('fa').agg(agg_vars)\n",
    "  input_list_no_trimestrales.append(df_input)\n",
    "# se crea el dataframe\n",
    "try:\n",
    "  df_no_trimestrales = pd.concat(input_list_no_trimestrales, axis=1, join='outer')\n",
    "except ValueError:\n",
    "  df_no_trimestrales = pd.DataFrame()\n",
    "\n",
    "# se unen las variables trimestrales con las no trimestrales transformadas\n",
    "df_list = []\n",
    "if len(df_trimestrales) > 0:\n",
    "  df_list.append(df_trimestrales)\n",
    "if len(df_no_trimestrales) > 0:\n",
    "  df_list.append(df_no_trimestrales)\n",
    "\n",
    "df = pd.concat(df_list, axis=1, join='outer')\n",
    "df.dropna(inplace=True)\n",
    "output_filepath = os.path.join(output_path, f'{target_var}_dataset.xlsx')\n",
    "df.to_excel(output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gasto_consumo_final_hogar_isflsh</th>\n",
       "      <th>ipc_total</th>\n",
       "      <th>tasa_int_lider_pm</th>\n",
       "      <th>oper_estab_mon_me</th>\n",
       "      <th>oper_estab_mon_mn</th>\n",
       "      <th>egreso_div_cap_imp</th>\n",
       "      <th>egreso_div_servicios_trans</th>\n",
       "      <th>egreso_div_transf_donaciones</th>\n",
       "      <th>egreso_div_turismo_viajes</th>\n",
       "      <th>ingreso_div_exp</th>\n",
       "      <th>...</th>\n",
       "      <th>taxs</th>\n",
       "      <th>comunic</th>\n",
       "      <th>finan</th>\n",
       "      <th>inmob</th>\n",
       "      <th>act_profes</th>\n",
       "      <th>servicios</th>\n",
       "      <th>ensenanza</th>\n",
       "      <th>salud</th>\n",
       "      <th>otr_act</th>\n",
       "      <th>tipo_cambio_de_referencia_gtq_usd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-03-31</th>\n",
       "      <td>9430.14</td>\n",
       "      <td>4.126667</td>\n",
       "      <td>4.126667</td>\n",
       "      <td>12.38</td>\n",
       "      <td>61924.3</td>\n",
       "      <td>3382780.66</td>\n",
       "      <td>20026.55</td>\n",
       "      <td>18423.77</td>\n",
       "      <td>229962.61</td>\n",
       "      <td>1773389.92</td>\n",
       "      <td>...</td>\n",
       "      <td>98.493333</td>\n",
       "      <td>93.153333</td>\n",
       "      <td>102.370000</td>\n",
       "      <td>98.206667</td>\n",
       "      <td>93.420000</td>\n",
       "      <td>302.79</td>\n",
       "      <td>112.383333</td>\n",
       "      <td>93.480000</td>\n",
       "      <td>94.913333</td>\n",
       "      <td>7.841923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>11800.43</td>\n",
       "      <td>4.396667</td>\n",
       "      <td>4.396667</td>\n",
       "      <td>13.19</td>\n",
       "      <td>62960.4</td>\n",
       "      <td>3519154.36</td>\n",
       "      <td>20557.10</td>\n",
       "      <td>25280.12</td>\n",
       "      <td>192368.52</td>\n",
       "      <td>1775236.16</td>\n",
       "      <td>...</td>\n",
       "      <td>98.383333</td>\n",
       "      <td>99.856667</td>\n",
       "      <td>98.396667</td>\n",
       "      <td>99.500000</td>\n",
       "      <td>99.180000</td>\n",
       "      <td>293.31</td>\n",
       "      <td>97.476667</td>\n",
       "      <td>99.463333</td>\n",
       "      <td>99.520000</td>\n",
       "      <td>7.800233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-30</th>\n",
       "      <td>12004.06</td>\n",
       "      <td>4.456667</td>\n",
       "      <td>4.456667</td>\n",
       "      <td>13.37</td>\n",
       "      <td>68802.7</td>\n",
       "      <td>3453331.68</td>\n",
       "      <td>18580.50</td>\n",
       "      <td>23445.33</td>\n",
       "      <td>130908.76</td>\n",
       "      <td>1451833.16</td>\n",
       "      <td>...</td>\n",
       "      <td>99.126667</td>\n",
       "      <td>97.943333</td>\n",
       "      <td>99.003333</td>\n",
       "      <td>100.263333</td>\n",
       "      <td>97.870000</td>\n",
       "      <td>277.23</td>\n",
       "      <td>103.570000</td>\n",
       "      <td>104.866667</td>\n",
       "      <td>104.113333</td>\n",
       "      <td>7.884067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>13766.49</td>\n",
       "      <td>4.390000</td>\n",
       "      <td>4.390000</td>\n",
       "      <td>13.17</td>\n",
       "      <td>67978.3</td>\n",
       "      <td>3439032.27</td>\n",
       "      <td>32281.93</td>\n",
       "      <td>29219.07</td>\n",
       "      <td>171191.35</td>\n",
       "      <td>1464416.88</td>\n",
       "      <td>...</td>\n",
       "      <td>103.996667</td>\n",
       "      <td>109.046667</td>\n",
       "      <td>100.226667</td>\n",
       "      <td>102.030000</td>\n",
       "      <td>109.530000</td>\n",
       "      <td>326.68</td>\n",
       "      <td>86.576667</td>\n",
       "      <td>102.186667</td>\n",
       "      <td>101.446667</td>\n",
       "      <td>7.907965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-31</th>\n",
       "      <td>10326.90</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>10.89</td>\n",
       "      <td>81291.4</td>\n",
       "      <td>3364878.23</td>\n",
       "      <td>10652.51</td>\n",
       "      <td>18461.20</td>\n",
       "      <td>218526.42</td>\n",
       "      <td>1721894.64</td>\n",
       "      <td>...</td>\n",
       "      <td>101.263333</td>\n",
       "      <td>97.380000</td>\n",
       "      <td>107.486667</td>\n",
       "      <td>102.290000</td>\n",
       "      <td>100.146667</td>\n",
       "      <td>315.95</td>\n",
       "      <td>113.450000</td>\n",
       "      <td>104.166667</td>\n",
       "      <td>99.783333</td>\n",
       "      <td>7.781481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gasto_consumo_final_hogar_isflsh  ipc_total  tasa_int_lider_pm  \\\n",
       "fa                                                                           \n",
       "2013-03-31                           9430.14   4.126667           4.126667   \n",
       "2013-06-30                          11800.43   4.396667           4.396667   \n",
       "2013-09-30                          12004.06   4.456667           4.456667   \n",
       "2013-12-31                          13766.49   4.390000           4.390000   \n",
       "2014-03-31                          10326.90   3.630000           3.630000   \n",
       "\n",
       "            oper_estab_mon_me  oper_estab_mon_mn  egreso_div_cap_imp  \\\n",
       "fa                                                                     \n",
       "2013-03-31              12.38            61924.3          3382780.66   \n",
       "2013-06-30              13.19            62960.4          3519154.36   \n",
       "2013-09-30              13.37            68802.7          3453331.68   \n",
       "2013-12-31              13.17            67978.3          3439032.27   \n",
       "2014-03-31              10.89            81291.4          3364878.23   \n",
       "\n",
       "            egreso_div_servicios_trans  egreso_div_transf_donaciones  \\\n",
       "fa                                                                     \n",
       "2013-03-31                    20026.55                      18423.77   \n",
       "2013-06-30                    20557.10                      25280.12   \n",
       "2013-09-30                    18580.50                      23445.33   \n",
       "2013-12-31                    32281.93                      29219.07   \n",
       "2014-03-31                    10652.51                      18461.20   \n",
       "\n",
       "            egreso_div_turismo_viajes  ingreso_div_exp  ...        taxs  \\\n",
       "fa                                                      ...               \n",
       "2013-03-31                  229962.61       1773389.92  ...   98.493333   \n",
       "2013-06-30                  192368.52       1775236.16  ...   98.383333   \n",
       "2013-09-30                  130908.76       1451833.16  ...   99.126667   \n",
       "2013-12-31                  171191.35       1464416.88  ...  103.996667   \n",
       "2014-03-31                  218526.42       1721894.64  ...  101.263333   \n",
       "\n",
       "               comunic       finan       inmob  act_profes  servicios  \\\n",
       "fa                                                                      \n",
       "2013-03-31   93.153333  102.370000   98.206667   93.420000     302.79   \n",
       "2013-06-30   99.856667   98.396667   99.500000   99.180000     293.31   \n",
       "2013-09-30   97.943333   99.003333  100.263333   97.870000     277.23   \n",
       "2013-12-31  109.046667  100.226667  102.030000  109.530000     326.68   \n",
       "2014-03-31   97.380000  107.486667  102.290000  100.146667     315.95   \n",
       "\n",
       "             ensenanza       salud     otr_act  \\\n",
       "fa                                               \n",
       "2013-03-31  112.383333   93.480000   94.913333   \n",
       "2013-06-30   97.476667   99.463333   99.520000   \n",
       "2013-09-30  103.570000  104.866667  104.113333   \n",
       "2013-12-31   86.576667  102.186667  101.446667   \n",
       "2014-03-31  113.450000  104.166667   99.783333   \n",
       "\n",
       "            tipo_cambio_de_referencia_gtq_usd  \n",
       "fa                                             \n",
       "2013-03-31                           7.841923  \n",
       "2013-06-30                           7.800233  \n",
       "2013-09-30                           7.884067  \n",
       "2013-12-31                           7.907965  \n",
       "2014-03-31                           7.781481  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvi02qwhziG0"
   },
   "source": [
    "## Procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1730863050969,
     "user": {
      "displayName": "Diego Alberto Morales Ibañez",
      "userId": "13208052402867133978"
     },
     "user_tz": 360
    },
    "id": "m8cASV9BbpH1"
   },
   "outputs": [],
   "source": [
    "def data_processing(df, target_var, t_samples, keep_all):\n",
    "    df_shifted = df[[target_var]].copy()\n",
    "    for n in range(1, t_samples + 1):\n",
    "        for col in df.columns:\n",
    "            df_shifted[f'{col}_t_{n}'] = df[col].shift(n)\n",
    "    df_shifted = df_shifted.dropna()\n",
    "\n",
    "    for col in df.columns:\n",
    "        df_shifted[f'{col}_prom_{t_samples}'] = df_shifted[[f'{col}_t_{i}' for i in range(1, t_samples + 1)]].mean(axis=1)\n",
    "        df_shifted[f'{col}_desv_{t_samples}'] = df_shifted[[f'{col}_t_{i}' for i in range(1, t_samples + 1)]].std(axis=1)\n",
    "        df_shifted[f'{col}_min_{t_samples}'] = df_shifted[[f'{col}_t_{i}' for i in range(1, t_samples + 1)]].min(axis=1)\n",
    "        df_shifted[f'{col}_max_{t_samples}'] = df_shifted[[f'{col}_t_{i}' for i in range(1, t_samples + 1)]].max(axis=1)\n",
    "        df_shifted[f'{col}_sum_{t_samples}'] = df_shifted[[f'{col}_t_{i}' for i in range(1, t_samples + 1)]].sum(axis=1)\n",
    "\n",
    "    if not keep_all:\n",
    "        columns_to_keep = [target_var] + [f'{col}_t_{1}' for col in df.columns] + \\\n",
    "                          [f'{col}_{agg}_{t_samples}' for col in df.columns for agg in ['prom', 'desv', 'min', 'max', 'sum']]\n",
    "        df_shifted = df_shifted[columns_to_keep]\n",
    "\n",
    "    return df_shifted\n",
    "\n",
    "df_shifted = data_processing(df, target_var, 4*3, keep_all=False)\n",
    "\n",
    "X = df_shifted.drop(columns=[target_var])\n",
    "y = df_shifted[target_var]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    X_train_scaled, \n",
    "    index=X_train.index,\n",
    "    columns=X_train.columns\n",
    ")\n",
    "\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    X_test_scaled, \n",
    "    index=X_test.index, \n",
    "    columns=X_test.columns\n",
    ")\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "X_train_pca = pd.DataFrame(\n",
    "    X_train_pca,\n",
    "    index=X_train.index,\n",
    "    columns=[f'PC{i+1}' for i in range(X_train_pca.shape[1])]\n",
    ")\n",
    "\n",
    "X_test_pca = pd.DataFrame(\n",
    "    X_test_pca,\n",
    "    index=X_test.index,\n",
    "    columns=[f'PC{i+1}' for i in range(X_test_pca.shape[1])]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_arima(y_train, X_train, p_values, d_values, q_values):\n",
    "    best_score, best_params, best_model = float(\"inf\"), None, None\n",
    "    \n",
    "    for p, d, q in product(p_values, d_values, q_values):\n",
    "        try:\n",
    "            model = ARIMA(y_train, order=(p, d, q), exog=X_train).fit()\n",
    "            if model.aic < best_score:\n",
    "                best_score, best_params, best_model = model.aic, (p, d, q), model\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    return best_model, best_params\n",
    "\n",
    "def arquitectura_ann(cant_capas, cant_neurons, learning_rate, input_dim):\n",
    "    model = Sequential([Input(shape=(input_dim,))])\n",
    "    for _ in range(cant_capas):\n",
    "        model.add(Dense(cant_neurons, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model\n",
    "\n",
    "def optimizar_ann(trial, X_train, y_train):\n",
    "    cant_capas = trial.suggest_int('cant_capas', 2, 8, 2)\n",
    "    cant_neurons = trial.suggest_int('cant_neurons', 8, 64, 8)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "    learning_rate = trial.suggest_categorical('learning_rate', [0.001,0.01, 0.1])\n",
    "    \n",
    "    model = arquitectura_ann(cant_capas, cant_neurons, learning_rate, X_train.shape[1])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    history = model.fit(\n",
    "        X_train, y_train, \n",
    "        validation_split=0.2,\n",
    "        epochs=100, batch_size=batch_size, verbose=0, callbacks=[early_stopping]\n",
    "    )\n",
    "    return min(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17224,
     "status": "ok",
     "timestamp": 1730866814305,
     "user": {
      "displayName": "Diego Alberto Morales Ibañez",
      "userId": "13208052402867133978"
     },
     "user_tz": 360
    },
    "id": "BNYnYkq3gdtm",
    "outputId": "c15db2f6-577e-4a81-a520-1644cdc833c0"
   },
   "outputs": [],
   "source": [
    "def train_models(X_train, X_test, y_train, y_test):\n",
    "    seed_value = 42\n",
    "    best_models = {}\n",
    "\n",
    "    p_values = range(1, 4)\n",
    "    model_ar, best_ar_params = optimize_arima(y_train.asfreq('QE'), X_train.asfreq('QE'), p_values, [0], [0])\n",
    "    best_models['ar'] = model_ar\n",
    "    print(f\"AR Best Parameters: {best_ar_params}\")\n",
    "\n",
    "    p_values = range(1, 4)\n",
    "    d_values = range(1, 4)\n",
    "    q_values = range(1, 4)\n",
    "    model_arima, best_arima_params = optimize_arima(y_train.asfreq('QE'), X_train.asfreq('QE'), p_values, d_values, q_values)\n",
    "    best_models['arima'] = model_arima\n",
    "    print(f\"ARIMA Best Parameters: {best_arima_params}\")\n",
    "\n",
    "    params_ridge = {'alpha': [0.1, 1.0, 10],\n",
    "        'random_state': [seed_value]}\n",
    "    grid_ridge = GridSearchCV(Ridge(), params_ridge, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_ridge.fit(X_train, y_train)\n",
    "    best_models['lr'] = grid_ridge.best_estimator_\n",
    "    print(f\"LR Ridge Best Parameters: {grid_ridge.best_params_}\")\n",
    "    \n",
    "    params_knn = {'n_neighbors': [3, 5, 7, 10],\n",
    "                  'weights': ['uniform', 'distance'],\n",
    "                  'metric': ['euclidean', 'manhattan', 'minkowski']}\n",
    "    grid_knn = GridSearchCV(KNeighborsRegressor(),\n",
    "                            params_knn, cv=3, scoring='neg_mean_squared_error',\n",
    "                            n_jobs=-1, verbose=0)\n",
    "    grid_knn.fit(X_train, y_train)\n",
    "    best_models['knn'] = grid_knn.best_estimator_\n",
    "    print(f\"KNN Best Parameters: {grid_knn.best_params_}\")\n",
    "\n",
    "    params_rf = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30],\n",
    "        'min_samples_split': [5, 10, 20],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'random_state': [seed_value]\n",
    "    }\n",
    "    grid_rf = GridSearchCV(RandomForestRegressor(),\n",
    "                           params_rf, cv=3, scoring='neg_mean_squared_error',\n",
    "                           n_jobs=-1, verbose=0)\n",
    "    grid_rf.fit(X_train, y_train)\n",
    "    best_models['rf'] = grid_rf.best_estimator_\n",
    "    print(f\"Random Forest Best Parameters: {grid_rf.best_params_}\")\n",
    "\n",
    "    params_xgb = {\n",
    "        'alpha': [0, 0.1, 1],\n",
    "        'lambda': [0, 0.1, 1],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7, 10, 15],\n",
    "        'random_state': [seed_value]\n",
    "    }\n",
    "    grid_xgb = GridSearchCV(xgb.XGBRegressor(n_jobs=-1),\n",
    "                            params_xgb,\n",
    "                            cv=3, scoring='neg_mean_squared_error',\n",
    "                            verbose=0)\n",
    "    grid_xgb.fit(X_train, y_train)\n",
    "    best_models['xgb'] = grid_xgb.best_estimator_\n",
    "    print(f\"XGBoost Best Parameters: {grid_xgb.best_params_}\")\n",
    "\n",
    "    study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "    study.optimize(\n",
    "        partial(optimizar_ann, X_train=X_train, y_train=y_train),\n",
    "        n_trials=30,\n",
    "        n_jobs=-1,\n",
    "        show_progress_bar=True)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    print(f\"ANN Best Parameters: {best_params}\")\n",
    "\n",
    "    model_ann = arquitectura_ann(best_params['cant_capas'], best_params['cant_neurons'], best_params['learning_rate'], X_train.shape[1])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    model_ann.fit(\n",
    "        X_train, y_train, \n",
    "        validation_split=0.2,\n",
    "        epochs=100, batch_size=best_params['batch_size'], verbose=0, callbacks=[early_stopping]\n",
    "    )\n",
    "    best_models['ann'] = model_ann\n",
    "\n",
    "    return best_models\n",
    "\n",
    "best_models = train_models(X_train_pca, X_test_pca, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 486,
     "status": "ok",
     "timestamp": 1730866840847,
     "user": {
      "displayName": "Diego Alberto Morales Ibañez",
      "userId": "13208052402867133978"
     },
     "user_tz": 360
    },
    "id": "sQjqABQLhIx3",
    "outputId": "86b813a9-80d5-4d51-c5ad-bac56b53fe89"
   },
   "outputs": [],
   "source": [
    "def evaluate(best_models, X_train, y_train, X_test, y_test, target_var):\n",
    "    results = {}\n",
    "    for name, model in best_models.items():\n",
    "        # Predicción y cálculo del MSE en el conjunto de entrenamiento\n",
    "        if name in ('ar', 'arima'):\n",
    "            y_train_pred = model.predict(start=0, end=len(y_train)-1, exog=X_train)\n",
    "        else:\n",
    "            y_train_pred = model.predict(X_train)\n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        \n",
    "        # Predicción y cálculo del MSE en el conjunto de prueba\n",
    "        if name in ('ar', 'arima'):\n",
    "            y_test_pred = model.predict(start=len(y_train), end=len(y_train)+len(y_test)-1, exog=X_test)\n",
    "        else:\n",
    "            y_test_pred = model.predict(X_test)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "        train_rmse = np.sqrt(train_mse)\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        \n",
    "        # Almacenar los resultados\n",
    "        results[name] = {\n",
    "            'y_train_pred': y_train_pred,\n",
    "            'train_rmse': train_rmse,\n",
    "            'y_test_pred': y_test_pred,\n",
    "            'test_rmse': test_rmse\n",
    "        }\n",
    "        \n",
    "        print(f\"{name}: train_rmse={train_rmse:,.2f}, test_rmse={test_rmse:,.2f}\")\n",
    "\n",
    "    best_model_name = min(results, key=lambda x: results[x]['test_rmse'])\n",
    "    best_model = best_models[best_model_name]\n",
    "    print(f\"Mejor modelo: {best_model_name}\")\n",
    "\n",
    "    export_path = os.path.join(output_path, 'models')\n",
    "    with open(os.path.join(export_path ,f\"{target_var}.pkl\"), \"wb\") as f:\n",
    "        joblib.dump(best_model, f)\n",
    "\n",
    "    print(f\"Modelo {target_var} exportado exitosamente.\")\n",
    "    return results\n",
    "\n",
    "results = evaluate(best_models, X_train_pca, y_train, X_test_pca, y_test, target_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1730866934965,
     "user": {
      "displayName": "Diego Alberto Morales Ibañez",
      "userId": "13208052402867133978"
     },
     "user_tz": 360
    },
    "id": "Zd3CRyoQrlCI",
    "outputId": "9d2e854b-3bfc-4440-c9df-95b26b0f6a7c"
   },
   "outputs": [],
   "source": [
    "def plot_comparison(results, target_var):\n",
    "    colors = {'ar' : 'brown',\n",
    "              'arima' : 'blue',\n",
    "              'lr' : 'red',\n",
    "              'knn' : 'orange',\n",
    "              'rf' : 'green',\n",
    "              'xgb' : 'purple',\n",
    "              'ann' : 'pink'}\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(y_test.values, label=\"Valores Reales (y_test)\", color=\"blue\")\n",
    "    \n",
    "    for name, result in results.items():\n",
    "        if name in ('ar', 'arima'):\n",
    "            plt.plot(result['y_test_pred'].reset_index(drop=True), label=f\"y_test_pred_{name}\", color=colors[name], linestyle=\"--\")\n",
    "        else:\n",
    "            plt.plot(result['y_test_pred'], label=f\"y_test_pred_{name}\", color=colors[name], linestyle=\"--\")\n",
    "\n",
    "    plt.xlabel(\"tiempo\")\n",
    "    plt.ylabel(target_var)\n",
    "    plt.title(f\"Resultados {target_var}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(output_path ,f'result_{target_var}.png'), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_comparison(results, target_var)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
